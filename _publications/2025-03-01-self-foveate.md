---
title: "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation"
collection: publications
category: conferences
permalink: /publication/2025-07-30-self-foveate
excerpt: 'This paper introduces Self-Foveate, an innovative LLM-driven method for instruction synthesis that uses multi-level foveation to enhance both diversity and difficulty of synthesized instructions from unsupervised text.'
date: 2025-07-30
venue: 'Findings of ACL 2025'
paperurl: 'https://arxiv.org/abs/2507.23440'
citation: 'Mingzhe Li, Xin Lu, Yanyan Zhao. (2025). &quot;Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation.&quot; <i>Findings of ACL 2025</i>.'
---

Large language models (LLMs) with instruction following capabilities have demonstrated impressive problem-solving abilities. While synthesizing instructional data from unsupervised text has become a common approach for training such models, conventional methods rely heavily on human effort for data annotation. Although existing automated synthesis paradigms have alleviated this constraint, they still exhibit significant limitations in ensuring adequate diversity and difficulty of synthesized instructions. 

To address these challenges, we propose Self-Foveate, an innovative LLM-driven method for instruction synthesis. This approach introduces a "Micro-Scatter-Macro" multi-level foveation methodology that effectively guides the LLM to deeply excavate fine-grained information embedded in unsupervised text, thereby enhancing both the diversity and difficulty of synthesized instructions. 

Comprehensive experiments across multiple unsupervised corpora and diverse model architectures validate the effectiveness and superiority of our proposed method.

**Links:**
- [ArXiv Paper](https://arxiv.org/abs/2507.23440)
- [GitHub Repository](https://github.com/Mubuky/self-foveate)
